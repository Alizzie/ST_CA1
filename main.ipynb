{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_datasets(url, dataset_name):\n",
    "    path_to_zip = tf.keras.utils.get_file(\n",
    "        fname=f\"{dataset_name}.tar.gz\",\n",
    "        origin=url,\n",
    "        extract=True)\n",
    "\n",
    "    path_to_zip = Path(path_to_zip)\n",
    "    path = path_to_zip.parent / dataset_name\n",
    "    return path_to_zip, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy from https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_batches(path, batchname):\n",
    "    batch_dic = unpickle(str(path / batchname))\n",
    "    batch_labels = batch_dic.get(b'labels')\n",
    "    batch_images = batch_dic.get(b'data')\n",
    "    batch_filenames = batch_dic.get(b'filenames')\n",
    "\n",
    "    print(f'{batchname}:')\n",
    "    print(batch_images.shape) # image as 3072 byte, 1024 each rgb channel\n",
    "\n",
    "    assert((len(batch_labels) == 10000)), 'labels contains not all 10000 labels'\n",
    "    assert((len(batch_images) == 10000)), 'images contains not all 10000 images'\n",
    "    assert((batch_images.shape[1] == 3072)), 'images are not in 3072 bytes'\n",
    "    assert((len(batch_filenames) == 10000)), 'filenames contains not all 10000 filenames'\n",
    "\n",
    "    for number, count in Counter(batch_labels).items():\n",
    "        print(f\"Number {number}: {count} occurrences\")\n",
    "    return batch_labels, batch_images, batch_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_labels_number(class_names, dic):\n",
    "    labels = dic.get(b'label_names')\n",
    "    labels = list(map(lambda x: x.decode('utf-8'), labels))\n",
    "    labels_nr = [index for index, value in enumerate(labels) if value in class_names]\n",
    "    return labels_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_class(classes, labels, images, filenames):\n",
    "    filtered_labels = [label for label in labels if label in classes]\n",
    "    filtered_images = [images[labels == cls] for cls in classes]\n",
    "    filtered_filenames = [filenames[labels == cls] for cls in classes]\n",
    "    return np.array(filtered_labels), np.array(filtered_images), np.array(filtered_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batchnames, batch_size, path):\n",
    "    data_labels = []\n",
    "    data_images = []\n",
    "    data_filenames = []\n",
    "\n",
    "    for name in batchnames:\n",
    "        labels, images, filenames = extract_batches(path, name)\n",
    "        data_labels.extend(labels)\n",
    "        data_images.extend(images)\n",
    "        data_filenames.extend(filenames)\n",
    "\n",
    "    assert((len(data_labels) == batch_size)), f'labels contains not all {batch_size} labels'\n",
    "    assert((len(data_images) == batch_size)), f'images contains not all {batch_size} images'\n",
    "    assert((len(data_filenames) == batch_size)), f'filenames contains not all {batch_size} filenames'\n",
    "\n",
    "    data_labels = np.array(data_labels)\n",
    "    data_images = np.array(data_images)\n",
    "    data_filenames = np.array(data_filenames)\n",
    "    data_labels, data_images, data_filenames = filter_class(selected_cifar10_classes, data_labels, data_images, data_filenames)\n",
    "    print(set(data_labels))\n",
    "    print(data_labels.shape)\n",
    "    print(data_images.shape)\n",
    "    print(data_filenames.shape)\n",
    "    return data_labels, data_images, data_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "cifar100_url = 'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'\n",
    "zip, cifar10_path = download_datasets(cifar10_url, 'cifar-10-batches-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "# class_labels: 1, 2, 3, 4, 5, 7, 9\n",
    "dic_file = 'batches.meta'\n",
    "needed_cifar10_classes = ['automobile', 'bird',  'cat', 'deer', 'dog', 'horse', 'truck']\n",
    "cifar10_dic = unpickle(str(cifar10_path / dic_file))\n",
    "selected_cifar10_classes = get_class_labels_number(['automobile', 'bird',  'cat', 'deer', 'dog', 'horse', 'truck'], cifar10_dic)\n",
    "print(selected_cifar10_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_batch_1:\n",
      "(10000, 3072)\n",
      "Number 6: 1030 occurrences\n",
      "Number 9: 981 occurrences\n",
      "Number 4: 999 occurrences\n",
      "Number 1: 974 occurrences\n",
      "Number 2: 1032 occurrences\n",
      "Number 7: 1001 occurrences\n",
      "Number 8: 1025 occurrences\n",
      "Number 3: 1016 occurrences\n",
      "Number 5: 937 occurrences\n",
      "Number 0: 1005 occurrences\n",
      "data_batch_2:\n",
      "(10000, 3072)\n",
      "Number 1: 1007 occurrences\n",
      "Number 6: 1008 occurrences\n",
      "Number 8: 987 occurrences\n",
      "Number 3: 995 occurrences\n",
      "Number 4: 1010 occurrences\n",
      "Number 0: 984 occurrences\n",
      "Number 5: 988 occurrences\n",
      "Number 2: 1010 occurrences\n",
      "Number 7: 1026 occurrences\n",
      "Number 9: 985 occurrences\n",
      "data_batch_3:\n",
      "(10000, 3072)\n",
      "Number 8: 961 occurrences\n",
      "Number 5: 1029 occurrences\n",
      "Number 0: 994 occurrences\n",
      "Number 6: 978 occurrences\n",
      "Number 9: 1029 occurrences\n",
      "Number 2: 965 occurrences\n",
      "Number 3: 997 occurrences\n",
      "Number 7: 1015 occurrences\n",
      "Number 4: 990 occurrences\n",
      "Number 1: 1042 occurrences\n",
      "data_batch_4:\n",
      "(10000, 3072)\n",
      "Number 0: 1003 occurrences\n",
      "Number 6: 1004 occurrences\n",
      "Number 2: 1041 occurrences\n",
      "Number 7: 981 occurrences\n",
      "Number 1: 963 occurrences\n",
      "Number 4: 1004 occurrences\n",
      "Number 5: 1021 occurrences\n",
      "Number 3: 976 occurrences\n",
      "Number 8: 1024 occurrences\n",
      "Number 9: 983 occurrences\n",
      "data_batch_5:\n",
      "(10000, 3072)\n",
      "Number 1: 1014 occurrences\n",
      "Number 8: 1003 occurrences\n",
      "Number 5: 1025 occurrences\n",
      "Number 7: 977 occurrences\n",
      "Number 4: 997 occurrences\n",
      "Number 3: 1016 occurrences\n",
      "Number 2: 952 occurrences\n",
      "Number 0: 1014 occurrences\n",
      "Number 9: 1022 occurrences\n",
      "Number 6: 980 occurrences\n",
      "{1, 2, 3, 4, 5, 7, 9}\n",
      "(35000,)\n",
      "(7, 5000, 3072)\n",
      "(7, 5000)\n",
      "test_batch:\n",
      "(10000, 3072)\n",
      "Number 3: 1000 occurrences\n",
      "Number 8: 1000 occurrences\n",
      "Number 0: 1000 occurrences\n",
      "Number 6: 1000 occurrences\n",
      "Number 1: 1000 occurrences\n",
      "Number 9: 1000 occurrences\n",
      "Number 5: 1000 occurrences\n",
      "Number 7: 1000 occurrences\n",
      "Number 4: 1000 occurrences\n",
      "Number 2: 1000 occurrences\n",
      "{1, 2, 3, 4, 5, 7, 9}\n",
      "(7000,)\n",
      "(7, 1000, 3072)\n",
      "(7, 1000)\n"
     ]
    }
   ],
   "source": [
    "batchnames = ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
    "cifar10_labels, cifar10_images, cifar10_filenames = get_data(batchnames, 50000, cifar10_path)\n",
    "cifar10_test_labels, cifar10_test_images, cifar10_test_filenames = get_data(['test_batch'], 10000, cifar10_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO :\n",
    "# First merge all datasets\n",
    "# Load images to rgb\n",
    "# get overview of images: number for each label, look of images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
