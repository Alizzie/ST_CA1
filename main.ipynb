{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_datasets(url, dataset_name):\n",
    "    path_to_zip = tf.keras.utils.get_file(\n",
    "        fname=f\"{dataset_name}.tar.gz\",\n",
    "        origin=url,\n",
    "        extract=True)\n",
    "\n",
    "    path_to_zip = Path(path_to_zip)\n",
    "    path = path_to_zip.parent / dataset_name\n",
    "    return path_to_zip, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy from https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cifar10_batches(path, batchname):\n",
    "    batch_dic = unpickle(str(path / batchname))\n",
    "    batch_labels = batch_dic.get(b'labels')\n",
    "    batch_images = batch_dic.get(b'data')\n",
    "    batch_filenames = batch_dic.get(b'filenames')\n",
    "\n",
    "    print(f'{batchname}:')\n",
    "    print(batch_images.shape) # image as 3072 byte, 1024 each rgb channel\n",
    "\n",
    "    assert((len(batch_labels) == 10000)), 'labels contains not all 10000 labels'\n",
    "    assert((len(batch_images) == 10000)), 'images contains not all 10000 images'\n",
    "    assert((batch_images.shape[1] == 3072)), 'images are not in 3072 bytes'\n",
    "    assert((len(batch_filenames) == 10000)), 'filenames contains not all 10000 filenames'\n",
    "\n",
    "    #for number, count in Counter(batch_labels).items():\n",
    "    #    print(f\"Number {number}: {count} occurrences\")\n",
    "    return batch_labels, batch_images, batch_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_dic(key, class_names, dic):\n",
    "    labels = dic.get(key)\n",
    "    labels = list(map(lambda x: x.decode('utf-8'), labels))\n",
    "    labels_nr = [index for index, value in enumerate(labels) if value in class_names]\n",
    "    labels =  [value for _, value in enumerate(labels) if value in class_names]\n",
    "    return labels, labels_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_class(classes, labels, images, filenames):\n",
    "    filtered_labels = [label for label in labels if label in classes]\n",
    "    filtered_images = [images[labels == cls] for cls in classes]\n",
    "    filtered_filenames = [filenames[labels == cls] for cls in classes]\n",
    "    return np.array(filtered_labels), np.array(filtered_images), np.array(filtered_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10_data(batchnames, batch_size, path):\n",
    "    data_labels = []\n",
    "    data_images = []\n",
    "    data_filenames = []\n",
    "\n",
    "    for name in batchnames:\n",
    "        labels, images, filenames = extract_cifar10_batches(path, name)\n",
    "        data_labels.extend(labels)\n",
    "        data_images.extend(images)\n",
    "        data_filenames.extend(filenames)\n",
    "\n",
    "    assert((len(data_labels) == batch_size)), f'labels contains not all {batch_size} labels'\n",
    "    assert((len(data_images) == batch_size)), f'images contains not all {batch_size} images'\n",
    "    assert((len(data_filenames) == batch_size)), f'filenames contains not all {batch_size} filenames'\n",
    "\n",
    "    data_labels = np.array(data_labels)\n",
    "    data_images = np.array(data_images)\n",
    "    data_filenames = np.array(data_filenames)\n",
    "    data_labels, data_images, data_filenames = filter_class(selected_cifar10_classes, data_labels, data_images, data_filenames)\n",
    "    print(set(data_labels))\n",
    "    print(data_labels.shape)\n",
    "    print(data_images.shape)\n",
    "    print(data_filenames.shape)\n",
    "    return data_labels, data_images, data_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "cifar100_url = 'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'\n",
    "zip, cifar10_path = download_datasets(cifar10_url, 'cifar-10-batches-py')\n",
    "zip, cifar100_path = download_datasets(cifar100_url, 'cifar-100-python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['automobile', 'bird', 'cat', 'deer', 'dog', 'horse', 'truck']\n",
      "[1, 2, 3, 4, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "# class_labels: 1, 2, 3, 4, 5, 7, 9\n",
    "dic_file = 'batches.meta'\n",
    "needed_cifar10_classes = ['automobile', 'bird',  'cat', 'deer', 'dog', 'horse', 'truck']\n",
    "cifar10_dic = unpickle(str(cifar10_path / dic_file))\n",
    "selected_cifar10_classnames, selected_cifar10_classes = get_classes_dic(b'label_names', needed_cifar10_classes, cifar10_dic)\n",
    "print(selected_cifar10_classnames)\n",
    "print(selected_cifar10_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_batch_1:\n",
      "(10000, 3072)\n",
      "data_batch_2:\n",
      "(10000, 3072)\n",
      "data_batch_3:\n",
      "(10000, 3072)\n",
      "data_batch_4:\n",
      "(10000, 3072)\n",
      "data_batch_5:\n",
      "(10000, 3072)\n",
      "{1, 2, 3, 4, 5, 7, 9}\n",
      "(35000,)\n",
      "(7, 5000, 3072)\n",
      "(7, 5000)\n",
      "test_batch:\n",
      "(10000, 3072)\n",
      "{1, 2, 3, 4, 5, 7, 9}\n",
      "(7000,)\n",
      "(7, 1000, 3072)\n",
      "(7, 1000)\n"
     ]
    }
   ],
   "source": [
    "batchnames = ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
    "cifar10_labels, cifar10_images, cifar10_filenames = get_cifar10_data(batchnames, 50000, cifar10_path)\n",
    "# Cifar10 Test data\n",
    "cifar10_test_labels, cifar10_test_images, cifar10_test_filenames = get_cifar10_data(['test_batch'], 10000, cifar10_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baby', 'bicycle', 'boy', 'bus', 'cattle', 'fox', 'girl', 'lawn_mower', 'man', 'motorcycle', 'pickup_truck', 'rabbit', 'squirrel', 'tractor', 'train', 'woman'] [2, 8, 11, 13, 19, 34, 35, 41, 46, 48, 58, 65, 80, 89, 90, 98]\n",
      "['trees'] [17]\n"
     ]
    }
   ],
   "source": [
    "# Cifar 100\n",
    "needed_cifar100_fine_classes = ['cattle', 'fox', 'baby', 'boy', 'girl', 'man', 'woman', 'rabbit', 'squirrel', 'bicycle', 'bus', 'motorcycle', 'pickup_truck',\n",
    "                                'train', 'lawn_mower', 'tractor']\n",
    "needed_cifar100_superclasses = ['trees']\n",
    "\n",
    "cifar100_dic = unpickle(str(cifar100_path / 'meta'))\n",
    "keys_list = list(cifar100_dic.keys())\n",
    "\n",
    "selected_cifar100_fine_classnames, selected_cifar100_fine_classes = get_classes_dic(keys_list[0], needed_cifar100_fine_classes, cifar100_dic)\n",
    "print(selected_cifar100_fine_classnames, selected_cifar100_fine_classes)\n",
    "\n",
    "selected_cifar100_superclassnames, selected_cifar100_superclasses = get_classes_dic(keys_list[1], needed_cifar100_superclasses, cifar100_dic)\n",
    "print(selected_cifar100_superclassnames, selected_cifar100_superclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> [b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data']\n",
      "(50000, 3072)\n"
     ]
    }
   ],
   "source": [
    "## Only one train batch\n",
    "cifar100_train_data = unpickle(str(cifar100_path / 'train'))\n",
    "print(type(cifar100_train_data), list(cifar100_train_data.keys()))\n",
    "\n",
    "\n",
    "batch_dic = unpickle(str(cifar100_path / 'train'))\n",
    "fine_labels = batch_dic.get(b'fine_labels')\n",
    "coarse_labels = batch_dic.get(b'coarse_labels')\n",
    "images = batch_dic.get(b'data')\n",
    "filenames = batch_dic.get(b'filenames')\n",
    "\n",
    "fine_labels = np.array(fine_labels)\n",
    "images = np.array(images)\n",
    "filenames = np.array(filenames)\n",
    "\n",
    "print(images.shape) # image as 3072 byte, 1024 each rgb channel\n",
    "\n",
    "assert((len(fine_labels) == 50000)), 'fine labels contains not all 10000 labels'\n",
    "assert((len(images) == 50000)), 'images contains not all 10000 images'\n",
    "assert((images.shape[1] == 3072)), 'images are not in 3072 bytes'\n",
    "assert((len(filenames) == 50000)), 'filenames contains not all 10000 filenames'\n",
    "assert((len(coarse_labels) == 50000)), 'coarse labels contains not all 10000 labels'\n",
    "\n",
    "# 2500 trees (17) images\n",
    "#for number, count in Counter(coarse_labels).items():\n",
    "#    print(f\"Number {number}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_fine_label = 101\n",
    "selected_cifar100_fine_classes.append(tree_fine_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 (50000, 3072)\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fine_labels)):\n",
    "    fine_labels[i] = tree_fine_label if coarse_labels[i] == 17 else fine_labels[i]\n",
    "\n",
    "#for number, count in Counter(fine_labels).items():\n",
    "#    print(f\"Number {number}: {count} occurrences\")\n",
    "\n",
    "fine_labels = np.array(fine_labels)\n",
    "print(len(images), images.shape)\n",
    "print(len(selected_cifar100_fine_classes))\n",
    "\n",
    "#test = np.array([images[fine_labels == cls ] for cls in selected_cifar100_fine_classes])\n",
    "#print(test.shape)\n",
    "#cifar100_labels, cifar100_images, cifar100_filenames = filter_class(selected_cifar100_fine_classes, fine_labels, images, filenames)\n",
    "#assert(set(selected_cifar100_fine_classes) == set(cifar100_labels)), 'filtered labels does not match with the needed one'\n",
    "#print(cifar100_images.shape)\n",
    "#print(cifar100_filenames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO :\n",
    "# Remap labels for merge\n",
    "# First merge all datasets\n",
    "# Load images to rgb\n",
    "# get overview of images: number for each label, look of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEA:\n",
    "# for superclass, change all fine_labels corresponding to superclass into one label (for avoiding label duplication, number >= 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
